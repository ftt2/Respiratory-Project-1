# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TDRrfXovKSSW2TUihA1nnuHPViG6oIjq
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

import matplotlib.pyplot as plt # for plotting
import torch.optim as optim #for gradient descent

import numpy as np
import time
import os
from torch.utils.data import DataLoader

import torchvision
from torchvision.datasets import DatasetFolder

import torchaudio

from data_loader import get_data_loader

'''
!sudo apt-get install sox libsox-dev libsox-fmt-all
!pip install git+https://github.com/pytorch/audio

from google.colab import drive
drive.mount('/content/drive')


# define training and test data directories
data_dir = '/content/drive/My Drive/Colab Notebooks/APS360_Project/'
'''

#helper function
def pad(x):
    padded = torch.zeros([40, 1727])
    padded[:, :x.size()[2]] = x.squeeze()
    return padded

'''
def get_data_loader(batch_size):
    tsfm = torchvision.transforms.Compose([
        lambda x: torchaudio.transforms.MFCC(x[1])(x[0]),  # MFCC
        lambda x: pad(x)])

    trainset = DatasetFolder(root='{}train/'.format(data_dir), loader=torchaudio.load,
                             extensions='.wav', transform=tsfm)

    valset = DatasetFolder(root='{}validation/'.format(data_dir), loader=torchaudio.load,
                             extensions='.wav', transform=tsfm)

    testset = DatasetFolder(root='{}test/'.format(data_dir), loader=torchaudio.load,
                             extensions='.wav', transform=tsfm)

    train_loader = DataLoader(trainset, batch_size=batch_size, num_workers=0, shuffle=True)
    val_loader = DataLoader(valset, batch_size=batch_size, num_workers=0, shuffle=True)
    test_loader = DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=True)

    return train_loader, val_loader, None
'''

class SVMClassifier(nn.Module):
    def __init__(self):
        super(SVMClassifier, self).__init__()
        self.layer1 = nn.Linear(40 * 1727, 6)

    def forward(self, img):
        flattened = img.view(-1, 40 * 1727)
        return self.layer1(flattened)

batch_sz = 64
train_loader, val_loader, test_loader = get_data_loader(batch_sz)

# Training
def get_model_name(name, batch_size, learning_rate, epoch):
    """ Generate a name for the model consisting of all the hyperparameter values
    Args:
        config: Configuration object containing the hyperparameters
    Returns:
        path: A string with the hyperparameter name and value concatenated
    """
    path = "model_{0}_bs{1}_lr{2}_epoch{3}".format(name,
                                                   batch_size,
                                                   learning_rate,
                                                   epoch)
    return path

def evaluate(net, loader, criterion):
    """ Evaluate the network on the validation set.
     Args:
         net: PyTorch neural network object
         loader: PyTorch data loader for the validation set
         criterion: The loss function
     Returns:
         err: A scalar for the avg classification error over the validation set
         loss: A scalar for the average loss function over the validation set
     """
    total_loss = 0.0
    total_err = 0.0
    total_epoch = 0
    for i, data in enumerate(loader, 0):
        inputs, labels = data
        if torch.cuda.is_available():
            inputs = inputs.cuda()
            labels = labels.cuda()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        corr = outputs.max(dim=1).indices.long() != labels
        total_err += int(corr.sum())
        total_loss += loss.item()
        total_epoch += len(labels)
    err = float(total_err) / total_epoch
    loss = float(total_loss) / (i + 1)
    return err, loss

###############################################################################
# Training Curve
def plot_training_curve(path):
    """ Plots the training curve for a model run, given the csv files
    containing the train/validation error/loss.
    Args:
        path: The base path of the csv files produced during training
    """
    train_err = np.loadtxt("{}_train_err.csv".format(path))
    val_err = np.loadtxt("{}_val_err.csv".format(path))
    train_loss = np.loadtxt("{}_train_loss.csv".format(path))
    val_loss = np.loadtxt("{}_val_loss.csv".format(path))
    plt.title("Train vs Validation Error")
    n = len(train_err) # number of epochs
    plt.plot(range(1,n+1), train_err, label="Train")
    plt.plot(range(1,n+1), val_err, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend(loc='best')
    plt.show()
    plt.title("Train vs Validation Loss")
    plt.plot(range(1,n+1), train_loss, label="Train")
    plt.plot(range(1,n+1), val_loss, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend(loc='best')
    plt.show()

def train_net(net, batch_size=64, learning_rate=0.01, num_epochs=30):
    # Fixed PyTorch random seed for reproducible result
    torch.manual_seed(360)
    ########################################################################
    # Obtain the PyTorch data loader objects to load batches of the datasets
    train_loader, val_loader, test_loader = get_data_loader(batch_size)
    ########################################################################
    criterion = torch.nn.MultiMarginLoss()
    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)
    #optimizer = optim.Adam(net.parameters(), lr=learning_rate)
    ########################################################################
    # Set up some numpy arrays to store the training/test loss/erruracy
    train_err = np.zeros(num_epochs)
    train_loss = np.zeros(num_epochs)
    val_err = np.zeros(num_epochs)
    val_loss = np.zeros(num_epochs)
    ########################################################################
    # Train the network
    # Loop over the data iterator and sample a new batch of training data
    # Get the output from the network, and optimize our loss function.
    start_time = time.time()
    for epoch in range(num_epochs):  # loop over the dataset multiple times
        total_train_loss = 0.0
        total_train_err = 0.0
        total_epoch = 0
        for i, data in enumerate(train_loader, 0):
            # Get the inputs
            inputs, labels = data
            if torch.cuda.is_available():
              inputs = inputs.cuda()
              labels = labels.cuda()

            # Zero the parameter gradients
            optimizer.zero_grad()
            # Forward pass, backward pass, and optimize
            outputs = net(inputs)
            loss = criterion(outputs, labels.long())
            print(loss.item())
            loss.backward()
            optimizer.step()
            # Calculate the statistics
            corr = outputs.max(dim=1).indices.long() != labels
            total_train_err += int(corr.sum())
            total_train_loss += loss.item()
            total_epoch += len(labels)
        train_err[epoch] = float(total_train_err)/total_epoch
        train_loss[epoch] = float(total_train_loss)/(i+1)
        val_err[epoch], val_loss[epoch] = evaluate(net, val_loader, criterion)
        print(("Epoch {}: Train err: {}, Train loss: {} |"+
               "Validation err: {}, Validation loss: {}").format(
                   epoch + 1,
                   train_err[epoch],
                   train_loss[epoch],
                   val_err[epoch],
                   val_loss[epoch]))
        # Save the current model (checkpoint) to a file
        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)
        torch.save(net.state_dict(), model_path)
    print('Finished Training')
    end_time = time.time()
    elapsed_time = end_time - start_time
    print("Total time elapsed: {:.2f} seconds".format(elapsed_time))
    # Write the train/test loss/err into CSV file for plotting later
    epochs = np.arange(1, num_epochs + 1)
    np.savetxt("{}_train_err.csv".format(model_path), train_err)
    np.savetxt("{}_train_loss.csv".format(model_path), train_loss)
    np.savetxt("{}_val_err.csv".format(model_path), val_err)
    np.savetxt("{}_val_loss.csv".format(model_path), val_loss)



model2 = SVMClassifier()
if torch.cuda.is_available():
  model2.cuda()
  print('CUDA is available!  Training on GPU ...')
else:
  print('CUDA is not available.  Training on CPU ...')
lr, bs, num_epo = 0.01, 64, 10
train_net(model2, batch_size=bs, learning_rate=lr, num_epochs=20)

path = get_model_name(model2.name, bs, lr, num_epo-1)